{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "135fbcca",
   "metadata": {},
   "source": [
    "# 文本分类实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3ca52d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1ac57a",
   "metadata": {},
   "source": [
    "# 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04ebe55a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                             review\n",
       "0      1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n",
       "1      1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n",
       "2      1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n",
       "3      1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n",
       "4      1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../ChnSentiCorp_htl_all.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d46172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7761</th>\n",
       "      <td>0</td>\n",
       "      <td>尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7762</th>\n",
       "      <td>0</td>\n",
       "      <td>盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7763</th>\n",
       "      <td>0</td>\n",
       "      <td>看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7764</th>\n",
       "      <td>0</td>\n",
       "      <td>我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>0</td>\n",
       "      <td>说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7765 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                             review\n",
       "0         1  距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较...\n",
       "1         1                       商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!\n",
       "2         1         早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。\n",
       "3         1  宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小...\n",
       "4         1               CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风\n",
       "...     ...                                                ...\n",
       "7761      0  尼斯酒店的几大特点：噪音大、环境差、配置低、服务效率低。如：1、隔壁歌厅的声音闹至午夜3点许...\n",
       "7762      0  盐城来了很多次，第一次住盐阜宾馆，我的确很失望整个墙壁黑咕隆咚的，好像被烟熏过一样家具非常的...\n",
       "7763      0  看照片觉得还挺不错的，又是4星级的，但入住以后除了后悔没有别的，房间挺大但空空的，早餐是有但...\n",
       "7764      0  我们去盐城的时候那里的最低气温只有4度，晚上冷得要死，居然还不开空调，投诉到酒店客房部，得到...\n",
       "7765      0  说实在的我很失望，之前看了其他人的点评后觉得还可以才去的，结果让我们大跌眼镜。我想这家酒店以...\n",
       "\n",
       "[7765 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna() #删除空数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fc93ea",
   "metadata": {},
   "source": [
    "# 创建dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb2859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ClassificationDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        super(ClassificationDataset, self).__init__() \n",
    "        self.data = pd.read_csv(data_path)\n",
    "        self.data = self.data.dropna()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data.iloc[index]['review'] , self.data.iloc[index]['label']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b8bd3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../ChnSentiCorp_htl_all.csv'\n",
    "dataset = ClassificationDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd39cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('距离川沙公路较近,但是公交指示不对,如果是\"蔡陆线\"的话,会非常麻烦.建议用别的路线.房间较为简单.', np.int64(1))\n",
      "('商务大床房，房间很大，床有2M宽，整体感觉经济实惠不错!', np.int64(1))\n",
      "('早餐太差，无论去多少人，那边也不加食品的。酒店应该重视一下这个问题了。房间本身很好。', np.int64(1))\n",
      "('宾馆在小街道上，不大好找，但还好北京热心同胞很多~宾馆设施跟介绍的差不多，房间很小，确实挺小，但加上低价位因素，还是无超所值的；环境不错，就在小胡同内，安静整洁，暖气好足-_-||。。。呵还有一大优势就是从宾馆出发，步行不到十分钟就可以到梅兰芳故居等等，京味小胡同，北海距离好近呢。总之，不错。推荐给节约消费的自助游朋友~比较划算，附近特色小吃很多~', np.int64(1))\n",
      "('CBD中心,周围没什么店铺,说5星有点勉强.不知道为什么卫生间没有电吹风', np.int64(1))\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(dataset[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf757c",
   "metadata": {},
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f779821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6212 1553 7765\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "train_dataset, val_dataset = random_split(dataset, [0.8, 0.2])\n",
    "print(len(train_dataset), len(val_dataset), len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5a704c",
   "metadata": {},
   "source": [
    "# 创建Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f751c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"hfl/rbt3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ab5cbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    texts,labels = zip(*batch)\n",
    "    inputs = tokenizer(texts, padding='max_length',max_length=128 , return_tensors=\"pt\", truncation=True)\n",
    "    inputs['labels'] = torch.tensor(labels)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5c434ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "trainloader = DataLoader(train_dataset, batch_size=32, shuffle=True,collate_fn=collate_fn)\n",
    "validloader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "894173b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " {'input_ids': tensor([[ 101, 6821, 3221,  ..., 3121,  857,  102],\n",
       "         [ 101, 6858, 6814,  ..., 2769, 2697,  102],\n",
       "         [ 101, 3680, 3613,  ...,    0,    0,    0],\n",
       "         ...,\n",
       "         [ 101, 1378, 7305,  ..., 1779, 1259,  102],\n",
       "         [ 101, 6983, 2421,  ...,    0,    0,    0],\n",
       "         [ 101, 3302, 1218,  ...,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "         1, 1, 1, 1, 0, 1, 1, 1])})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(enumerate(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb2b25c",
   "metadata": {},
   "source": [
    "### 创建模型和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd959555",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at hfl/rbt3 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"hfl/rbt3\").cuda()\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80464ed4",
   "metadata": {},
   "source": [
    "## 训练与验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5d4c7142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalaluate():\n",
    "    model.eval()\n",
    "    acc_num = 0\n",
    "    with torch.inference_mode():\n",
    "        for batch in validloader:\n",
    "            batch ={k:v.cuda() for k,v in batch.items()}\n",
    "            outputs = model(**batch)   \n",
    "            pred = torch.argmax(outputs.logits, dim=-1)\n",
    "            acc_num += (pred.long() == batch[\"labels\"].long()).long().float().sum()\n",
    "    return acc_num / len(val_dataset)\n",
    "\n",
    "def train(epochs=5, log_step=10):\n",
    "    global_step = 0\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for batch in trainloader:\n",
    "            batch ={k:v.cuda() for k,v in batch.items()}\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(**batch)\n",
    "            outputs.loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "            if global_step % log_step == 0:\n",
    "                print(f\"epoch: {epoch}, step: {global_step}, loss: {outputs.loss.item()}\")\n",
    "        acc = evalaluate()\n",
    "        print(f\"epoch: {epoch}, acc: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262f38f",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "679abd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, step: 10, loss: 0.63782799243927\n",
      "epoch: 0, step: 20, loss: 0.6574102640151978\n",
      "epoch: 0, step: 30, loss: 0.5512548089027405\n",
      "epoch: 0, step: 40, loss: 0.35392865538597107\n",
      "epoch: 0, step: 50, loss: 0.26514166593551636\n",
      "epoch: 0, step: 60, loss: 0.558419406414032\n",
      "epoch: 0, step: 70, loss: 0.544950008392334\n",
      "epoch: 0, step: 80, loss: 0.2635766267776489\n",
      "epoch: 0, step: 90, loss: 0.4154847264289856\n",
      "epoch: 0, step: 100, loss: 0.26677951216697693\n",
      "epoch: 0, step: 110, loss: 0.15649542212486267\n",
      "epoch: 0, step: 120, loss: 0.3686162829399109\n",
      "epoch: 0, step: 130, loss: 0.2954069674015045\n",
      "epoch: 0, step: 140, loss: 0.27229002118110657\n",
      "epoch: 0, step: 150, loss: 0.23543420433998108\n",
      "epoch: 0, step: 160, loss: 0.22024647891521454\n",
      "epoch: 0, step: 170, loss: 0.2670241594314575\n",
      "epoch: 0, step: 180, loss: 0.36892426013946533\n",
      "epoch: 0, step: 190, loss: 0.2929568588733673\n",
      "epoch: 0, acc: 0.8718609809875488\n",
      "epoch: 1, step: 200, loss: 0.2824801206588745\n",
      "epoch: 1, step: 210, loss: 0.3723704218864441\n",
      "epoch: 1, step: 220, loss: 0.23291130363941193\n",
      "epoch: 1, step: 230, loss: 0.22974707186222076\n",
      "epoch: 1, step: 240, loss: 0.10517045855522156\n",
      "epoch: 1, step: 250, loss: 0.1584814041852951\n",
      "epoch: 1, step: 260, loss: 0.13500313460826874\n",
      "epoch: 1, step: 270, loss: 0.422542929649353\n",
      "epoch: 1, step: 280, loss: 0.26270797848701477\n",
      "epoch: 1, step: 290, loss: 0.13067960739135742\n",
      "epoch: 1, step: 300, loss: 0.41370686888694763\n",
      "epoch: 1, step: 310, loss: 0.18064294755458832\n",
      "epoch: 1, step: 320, loss: 0.19133073091506958\n",
      "epoch: 1, step: 330, loss: 0.193211168050766\n",
      "epoch: 1, step: 340, loss: 0.3916972577571869\n",
      "epoch: 1, step: 350, loss: 0.20961692929267883\n",
      "epoch: 1, step: 360, loss: 0.27088314294815063\n",
      "epoch: 1, step: 370, loss: 0.1024758592247963\n",
      "epoch: 1, step: 380, loss: 0.10973682999610901\n",
      "epoch: 1, step: 390, loss: 0.015924133360385895\n",
      "epoch: 1, acc: 0.8815196752548218\n",
      "epoch: 2, step: 400, loss: 0.3587435185909271\n",
      "epoch: 2, step: 410, loss: 0.09203310310840607\n",
      "epoch: 2, step: 420, loss: 0.11534622311592102\n",
      "epoch: 2, step: 430, loss: 0.08538636565208435\n",
      "epoch: 2, step: 440, loss: 0.15632158517837524\n",
      "epoch: 2, step: 450, loss: 0.10016356408596039\n",
      "epoch: 2, step: 460, loss: 0.14343178272247314\n",
      "epoch: 2, step: 470, loss: 0.375486820936203\n",
      "epoch: 2, step: 480, loss: 0.09088785946369171\n",
      "epoch: 2, step: 490, loss: 0.13270312547683716\n",
      "epoch: 2, step: 500, loss: 0.3132122755050659\n",
      "epoch: 2, step: 510, loss: 0.08760295808315277\n",
      "epoch: 2, step: 520, loss: 0.15001876652240753\n",
      "epoch: 2, step: 530, loss: 0.34409141540527344\n",
      "epoch: 2, step: 540, loss: 0.25950297713279724\n",
      "epoch: 2, step: 550, loss: 0.34511688351631165\n",
      "epoch: 2, step: 560, loss: 0.1207708939909935\n",
      "epoch: 2, step: 570, loss: 0.09941209852695465\n",
      "epoch: 2, step: 580, loss: 0.1158570647239685\n",
      "epoch: 2, acc: 0.8808757662773132\n",
      "epoch: 3, step: 590, loss: 0.18636438250541687\n",
      "epoch: 3, step: 600, loss: 0.1101960688829422\n",
      "epoch: 3, step: 610, loss: 0.1548207849264145\n",
      "epoch: 3, step: 620, loss: 0.1958838701248169\n",
      "epoch: 3, step: 630, loss: 0.07206901162862778\n",
      "epoch: 3, step: 640, loss: 0.12931811809539795\n",
      "epoch: 3, step: 650, loss: 0.07223990559577942\n",
      "epoch: 3, step: 660, loss: 0.10577418655157089\n",
      "epoch: 3, step: 670, loss: 0.2275940477848053\n",
      "epoch: 3, step: 680, loss: 0.14883911609649658\n",
      "epoch: 3, step: 690, loss: 0.03517230600118637\n",
      "epoch: 3, step: 700, loss: 0.1555905044078827\n",
      "epoch: 3, step: 710, loss: 0.26721176505088806\n",
      "epoch: 3, step: 720, loss: 0.17086948454380035\n",
      "epoch: 3, step: 730, loss: 0.07300238311290741\n",
      "epoch: 3, step: 740, loss: 0.16779959201812744\n",
      "epoch: 3, step: 750, loss: 0.3078574538230896\n",
      "epoch: 3, step: 760, loss: 0.15437346696853638\n",
      "epoch: 3, step: 770, loss: 0.10100936889648438\n",
      "epoch: 3, step: 780, loss: 0.12163029611110687\n",
      "epoch: 3, acc: 0.8866710066795349\n",
      "epoch: 4, step: 790, loss: 0.0454440638422966\n",
      "epoch: 4, step: 800, loss: 0.02484956569969654\n",
      "epoch: 4, step: 810, loss: 0.06919001042842865\n",
      "epoch: 4, step: 820, loss: 0.07803940773010254\n",
      "epoch: 4, step: 830, loss: 0.05229940265417099\n",
      "epoch: 4, step: 840, loss: 0.04673151299357414\n",
      "epoch: 4, step: 850, loss: 0.056797903031110764\n",
      "epoch: 4, step: 860, loss: 0.30803337693214417\n",
      "epoch: 4, step: 870, loss: 0.08478827029466629\n",
      "epoch: 4, step: 880, loss: 0.06444026529788971\n",
      "epoch: 4, step: 890, loss: 0.08043947070837021\n",
      "epoch: 4, step: 900, loss: 0.05309298634529114\n",
      "epoch: 4, step: 910, loss: 0.11420530080795288\n",
      "epoch: 4, step: 920, loss: 0.17811955511569977\n",
      "epoch: 4, step: 930, loss: 0.03513217717409134\n",
      "epoch: 4, step: 940, loss: 0.09784762561321259\n",
      "epoch: 4, step: 950, loss: 0.06785383820533752\n",
      "epoch: 4, step: 960, loss: 0.02182205766439438\n",
      "epoch: 4, step: 970, loss: 0.025743218138813972\n",
      "epoch: 4, acc: 0.8757244348526001\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfcd31b",
   "metadata": {},
   "source": [
    "## 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e2298f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入：我觉得这家酒店不错 \n",
      " 模型预测结果：tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "seq = '我觉得这家酒店不错'\n",
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    inputs = tokenizer(seq, return_tensors=\"pt\")\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    logits = model(**inputs).logits\n",
    "    prdict = torch.argmax(logits, dim=-1)\n",
    "    print(f'输入：{seq} \\n 模型预测结果：{prdict}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "974b7571",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'positive', 'score': 0.998591959476471}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import  pipeline\n",
    "model.config.id2label = {0: 'negative', 1: 'positive'}\n",
    "pipe = pipeline(\"text-classification\", model=model ,tokenizer=tokenizer, device=0)\n",
    "pipe(seq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
