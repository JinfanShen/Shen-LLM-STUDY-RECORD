{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "839047be",
   "metadata": {},
   "source": [
    "# 多项选择任务:  \n",
    "即给一个文本`Context`,然后给一个列表`Choices`,然后让网络选择一个`Choice`。  \n",
    "本质上是一项分类任务。\n",
    "# 基于Transformers的实现\n",
    "## 数据预处理\n",
    "处理格式：  \n",
    "[CLS]1 [Context] [SEP] [Question] [Choice1] [SEP]  \n",
    "[CLS]2 [Context] [SEP] [Question] [Choice2] [SEP]  \n",
    "[CLS]3 [Context] [SEP] [Question] [Choice3] [SEP]  \n",
    "[CLS]4 [Context] [SEP] [Question] [Choice4] [SEP]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2ca86",
   "metadata": {},
   "source": [
    "以bert模型进行的多项选择任务：\n",
    "```python\n",
    "class BertForMultipleChoice(BertPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        classifier_dropout = (\n",
    "            config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "        )\n",
    "        self.dropout = nn.Dropout(classifier_dropout)\n",
    "        self.classifier = nn.Linear(config.hidden_size, 1)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    @auto_docstring\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[tuple[torch.Tensor], MultipleChoiceModelOutput]:\n",
    "        r\"\"\"\n",
    "        input_ids (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`):\n",
    "            Indices of input sequence tokens in the vocabulary.\n",
    "\n",
    "            Indices can be obtained using [`AutoTokenizer`]. See [`PreTrainedTokenizer.encode`] and\n",
    "            [`PreTrainedTokenizer.__call__`] for details.\n",
    "\n",
    "            [What are input IDs?](../glossary#input-ids)\n",
    "        token_type_ids (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`, *optional*):\n",
    "            Segment token indices to indicate first and second portions of the inputs. Indices are selected in `[0,\n",
    "            1]`:\n",
    "\n",
    "            - 0 corresponds to a *sentence A* token,\n",
    "            - 1 corresponds to a *sentence B* token.\n",
    "\n",
    "            [What are token type IDs?](../glossary#token-type-ids)\n",
    "        position_ids (`torch.LongTensor` of shape `(batch_size, num_choices, sequence_length)`, *optional*):\n",
    "            Indices of positions of each input sequence tokens in the position embeddings. Selected in the range `[0,\n",
    "            config.max_position_embeddings - 1]`.\n",
    "\n",
    "            [What are position IDs?](../glossary#position-ids)\n",
    "        inputs_embeds (`torch.FloatTensor` of shape `(batch_size, num_choices, sequence_length, hidden_size)`, *optional*):\n",
    "            Optionally, instead of passing `input_ids` you can choose to directly pass an embedded representation. This\n",
    "            is useful if you want more control over how to convert `input_ids` indices into associated vectors than the\n",
    "            model's internal embedding lookup matrix.\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the multiple choice classification loss. Indices should be in `[0, ...,\n",
    "            num_choices-1]` where `num_choices` is the size of the second dimension of the input tensors. (See\n",
    "            `input_ids` above)\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        num_choices = input_ids.shape[1] if input_ids is not None else inputs_embeds.shape[1]\n",
    "\n",
    "        input_ids = input_ids.view(-1, input_ids.size(-1)) if input_ids is not None else None  #[batch_size * num_choices, sequence_length]\n",
    "        attention_mask = attention_mask.view(-1, attention_mask.size(-1)) if attention_mask is not None else None\n",
    "        token_type_ids = token_type_ids.view(-1, token_type_ids.size(-1)) if token_type_ids is not None else None\n",
    "        position_ids = position_ids.view(-1, position_ids.size(-1)) if position_ids is not None else None\n",
    "        inputs_embeds = (\n",
    "            inputs_embeds.view(-1, inputs_embeds.size(-2), inputs_embeds.size(-1))\n",
    "            if inputs_embeds is not None\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1] # [batch * num_choices, hidden_size]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)  # [batch * num_choices, 1]\n",
    "        reshaped_logits = logits.view(-1, num_choices)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(reshaped_logits, labels)\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (reshaped_logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return MultipleChoiceModelOutput(\n",
    "            loss=loss,\n",
    "            logits=reshaped_logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537def42",
   "metadata": {},
   "source": [
    "# step1 导入相关包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "32ce4e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  AutoTokenizer, AutoModelForMultipleChoice, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e22fe0",
   "metadata": {},
   "source": [
    "# step2 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64fca0bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 11869\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'context', 'question', 'choice', 'answer'],\n",
       "        num_rows: 3816\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = load_dataset(\"../dataset/clue_c3\")\n",
    "datasets.pop(\"test\")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66141887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 0,\n",
       " 'context': ['男：你今天晚上有时间吗?我们一起去看电影吧?', '女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……'],\n",
       " 'question': '女的最喜欢哪种电影?',\n",
       " 'choice': ['恐怖片', '爱情片', '喜剧片', '科幻片'],\n",
       " 'answer': '喜剧片'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81c311",
   "metadata": {},
   "source": [
    "# step3 数据集预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e721ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='hfl/chinese-macbert-base', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('hfl/chinese-macbert-base')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b0260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'男：你今天晚上有时间吗?我们一起去看电影吧? 女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = ['男：你今天晚上有时间吗?我们一起去看电影吧?', '女：你喜欢恐怖片和爱情片，但是我喜欢喜剧片，科幻片一般。所以……']\n",
    "\n",
    "b = '\\n'.join(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7a78e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(examples):\n",
    "    # 按照上面画的对Question和choice进行配对\n",
    "    context = []\n",
    "    q_c     = []\n",
    "    labels  = []\n",
    "    for  idx in range(len(examples['context'])):\n",
    "        ctx = \"\\n\".join(examples['context'][idx])\n",
    "        que = examples['question'][idx]\n",
    "        choices = examples['choice'][idx]\n",
    "        for choice in choices:\n",
    "            context.append(ctx)\n",
    "            q_c.append(que + \" \" + choice)\n",
    "        if len(choices) < 4:\n",
    "            for _ in range(4 - len(choices)):\n",
    "                context.append(ctx)\n",
    "                q_c.append(que + \" \" + \"padding\")\n",
    "        labels.append(choices.index(examples['answer'][idx])) # 答案的索引\n",
    "    tokenized_examples = tokenizer(context, q_c, truncation=\"only_first\", max_length=256, padding=\"max_length\")\n",
    "    # 模型希望的输入是[batch, num_choices, sequence_length] 这里现在是[batch*num_choices, sequence_length]\n",
    "    tokenized_examples = {k: [v[i:i+4]for i in range(0, len(v),4)]for k, v in tokenized_examples.items()}\n",
    "    tokenized_examples[\"labels\"] = labels\n",
    "    return tokenized_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e18b9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "tk_ds = datasets.map(function=process_function, batched=True, remove_columns=datasets['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca13b537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask', 'labels']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_ds['train'].column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cde9ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4, 256)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(tk_ds['train'][0:30]['input_ids']).shape  # 数据形状处理正确"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dac7b4b",
   "metadata": {},
   "source": [
    "# step4 创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daeb7663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at hfl/chinese-macbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForMultipleChoice(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForMultipleChoice.from_pretrained('hfl/chinese-macbert-base')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3e255c",
   "metadata": {},
   "source": [
    "# step5 创建评估函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb6aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a4669",
   "metadata": {},
   "source": [
    "# step6 配置训练参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7bacc533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "average_tokens_across_devices=True,\n",
       "batch_eval_metrics=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_persistent_workers=False,\n",
       "dataloader_pin_memory=True,\n",
       "dataloader_prefetch_factor=None,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=False,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_do_concat_batches=True,\n",
       "eval_on_start=False,\n",
       "eval_steps=None,\n",
       "eval_strategy=epoch,\n",
       "eval_use_gather_object=False,\n",
       "fp16=True,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=32,\n",
       "gradient_checkpointing=False,\n",
       "gradient_checkpointing_kwargs=None,\n",
       "greater_is_better=True,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=None,\n",
       "hub_revision=None,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_for_metrics=[],\n",
       "include_inputs_for_metrics=False,\n",
       "include_num_input_tokens_seen=no,\n",
       "include_tokens_per_second=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=5e-05,\n",
       "length_column_name=length,\n",
       "liger_kernel_config=None,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=./muliple_choice\\runs\\Jan21_22-43-04_LAPTOP-BREMT5S6,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=50,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_kwargs={},\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=accuracy,\n",
       "mp_parameters=,\n",
       "neftune_noise_alpha=None,\n",
       "no_cuda=False,\n",
       "num_train_epochs=3,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "optim_target_modules=None,\n",
       "output_dir=./muliple_choice,\n",
       "overwrite_output_dir=False,\n",
       "parallelism_config=None,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=16,\n",
       "per_device_train_batch_size=8,\n",
       "prediction_loss_only=False,\n",
       "project=huggingface,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=['tensorboard'],\n",
       "restore_callback_states_from_checkpoint=False,\n",
       "resume_from_checkpoint=None,\n",
       "run_name=runs,\n",
       "save_on_each_node=False,\n",
       "save_only_model=False,\n",
       "save_safetensors=True,\n",
       "save_steps=500,\n",
       "save_strategy=epoch,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torch_empty_cache_steps=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "trackio_space_id=trackio,\n",
       "use_cpu=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_liger_kernel=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=0,\n",
       "weight_decay=0.0,\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"./muliple_choice\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=32,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    run_name='runs',\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    fp16=True,\n",
    ")\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be27d6e",
   "metadata": {},
   "source": [
    "# step7 创建训练器并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecd21dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=tk_ds['train'],\n",
    "    eval_dataset=tk_ds['validation'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b4c6d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='141' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [141/141 23:28, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.050376</td>\n",
       "      <td>0.529350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.206100</td>\n",
       "      <td>0.979254</td>\n",
       "      <td>0.574423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.954200</td>\n",
       "      <td>1.003142</td>\n",
       "      <td>0.585954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=141, training_loss=1.0065639847559287, metrics={'train_runtime': 1419.0503, 'train_samples_per_second': 25.092, 'train_steps_per_second': 0.099, 'total_flos': 1.873702246273229e+16, 'train_loss': 1.0065639847559287, 'epoch': 3.0})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b835c09",
   "metadata": {},
   "source": [
    "# step8 模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b5696d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class MultipleChoicePipeline:\n",
    "\n",
    "    def __init__(self, model, tokenizer) -> None:\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = model.device\n",
    "    \n",
    "    def preprocess(self, context, question, choices):\n",
    "        ctxs, qcs = [], []\n",
    "        for choice in choices:\n",
    "            ctxs.append(context)\n",
    "            qcs.append(question + \" \" + choice)\n",
    "        return self.tokenizer(ctxs, \n",
    "                            qcs, \n",
    "                            truncation='only_first', \n",
    "                            padding=\"max_length\", \n",
    "                            max_length=256,\n",
    "                            return_tensors=\"pt\")\n",
    "\n",
    "    def prediction(self, inputs):\n",
    "        inputs = {k: v.unsqueeze(0).to(self.device) for k, v in inputs.items()}\n",
    "        return self.model(**inputs).logits\n",
    "\n",
    "    def postprocess(self, logits, choices):\n",
    "        prediction = torch.argmax(logits, dim=-1).cpu().item()\n",
    "        return choices[prediction]\n",
    "        \n",
    "    \n",
    "    def __call__(self, context, question, choices):\n",
    "        inputs = self.preprocess(context, question, choices)\n",
    "        logits = self.prediction(inputs)\n",
    "        result = self.postprocess(logits, choices)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "141ab8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = MultipleChoicePipeline(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e9d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"小明在北京上班，但是他住在河北，所以他每天要在两地奔波。\"\n",
    "question = \"小明在哪上班\"\n",
    "choices   = [\"北京\", \"河北\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9951a98b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'从北京到河北'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe(context, question, choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68c9276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
